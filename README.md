

# NSFWDetectorKit

A small Swift Package wrapping a Core ML model for **NSFW (Not Safe For Work)** content detection.  
ğŸ‘‰ It allows you to classify images as **explicit (unsafe)** or **safe** based on a configurable threshold.

Bu Swift Package, Core ML tabanlÄ± bir **NSFW (mÃ¼stehcen iÃ§erik)** tespit modelini sarar.  
ğŸ‘‰ GÃ¶rselleri **mÃ¼stehcen (yayÄ±nlanamaz)** veya **gÃ¼venli (yayÄ±nlanabilir)** olarak sÄ±nÄ±flandÄ±rmanÄ±za olanak tanÄ±r.

---

## ğŸ“¦ Installation (SPM)

1. Xcode â†’ **File â–¸ Add Packagesâ€¦**  
2. Repository URL:
   ```
   https://github.com/mehmettirpan/NSFWDetectorKit.git
   ```
3. Dependency Rule: *Up to Next Major Version* (Ã¶nerilir)  
4. Kodda import:
   ```swift
   import NSFWDetectorKit
   ```

---

## âš™ï¸ Requirements
- iOS 15.0+  
- Xcode 15+  
- Swift 5.9+  
- Core ML model file included: `NSFWDetector.mlpackage`

---

## ğŸš€ Usage

### Classify with UIImage
```swift
import NSFWDetectorKit

let image: UIImage = ... // e.g. from photo library

CoreMLNSFWScanner.shared.classify(image) { result in
    switch result {
    case .success(let (score, labels)):
        print("NSFW probability =", score)
        print("All labels =", labels)
    case .failure(let error):
        print("Error:", error)
    }
}
```

### Classify with Threshold
```swift
let threshold: Float = 0.20 // adjust as you wish

CoreMLNSFWScanner.shared.classify(image, threshold: threshold) { result in
    switch result {
    case .success(let (blocked, score, labels)):
        print("NSFW probability =", score)
        print("Blocked? =", blocked ? "âŒ Not allowed" : "âœ… Allowed")
    case .failure(let error):
        print("Error:", error)
    }
}
```

### Classify with CGImage (UIKit-free)
```swift
let cg: CGImage = ...
CoreMLNSFWScanner.shared.classify(
    cgImage: cg,
    orientation: .up
) { result in
    switch result {
    case .success(let (score, labels)):
        print("NSFW probability =", score)
        print("Labels =", labels)
    case .failure(let error):
        print("Error:", error)
    }
}
```

---

## ğŸ“ Notes
- `score` aralÄ±ÄŸÄ±: `0.0` (gÃ¼venli) â†’ `1.0` (mÃ¼stehcen).  
- EÅŸik tamamen uygulamaya baÄŸlÄ±dÄ±r:
  - **0.20** â†’ sÄ±kÄ± (borderline iÃ§eriklerin Ã§oÄŸunu engeller)
  - **0.50** â†’ dengeli
  - **0.80** â†’ esnek  
- Performans cihaz donanÄ±mÄ±na baÄŸlÄ±dÄ±r (Apple Neural Engine hÄ±zlandÄ±rÄ±r).

---

## ğŸ“‚ Project Structure
```
Package.swift
Sources/NSFWDetectorKit/
 â”œâ”€â”€ CoreMLNSFWScanner.swift
 â”œâ”€â”€ NSFWDetectorKit.swift
 â””â”€â”€ NSFWDetector.mlpackage
```

---

## ğŸ“„ License
MIT â€” see [LICENSE](LICENSE).